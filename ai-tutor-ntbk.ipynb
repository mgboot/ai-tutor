{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz Evaluator/Tutor Agent\n",
    "\n",
    "This notebook demonstrates how to create a Quiz Evaluator/Tutor agent using Semantic Kernel.\n",
    "The agent evaluates student answers against ground truth answers and provides insights into potential misunderstandings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "# !pip install semantic-kernel>=1.3.0 nest-asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment\n",
    "\n",
    "Configure the environment variables for authentication with your AI service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Setup for Azure OpenAI\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"] = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Alternatively, for OpenAI\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Uncomment and configure one of the above sections based on your preferred AI service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Create Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Add the appropriate AI service\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# For Azure OpenAI\u001b[39;00m\n\u001b[0;32m     20\u001b[0m service_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquiz-evaluator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m kernel\u001b[38;5;241m.\u001b[39madd_service(\n\u001b[0;32m     22\u001b[0m     AzureChatCompletion(\n\u001b[0;32m     23\u001b[0m         service_id\u001b[38;5;241m=\u001b[39mservice_id,\n\u001b[1;32m---> 24\u001b[0m         deployment_name\u001b[38;5;241m=\u001b[39m\u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_OPENAI_DEPLOYMENT_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     25\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_OPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     26\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_OPENAI_ENDPOINT\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     27\u001b[0m     )\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# For OpenAI\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# kernel.add_service(\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#     OpenAIChatCompletion(\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "# Choose the appropriate AI service connector\n",
    "# For Azure OpenAI\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "# For OpenAI\n",
    "# from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "# Create the kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Add the appropriate AI service\n",
    "# For Azure OpenAI\n",
    "service_id = \"quiz-evaluator\"\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=service_id,\n",
    "        deployment_name=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "        api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "        endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# For OpenAI\n",
    "# kernel.add_service(\n",
    "#     OpenAIChatCompletion(\n",
    "#         service_id=service_id,\n",
    "#         ai_model_id=\"gpt-4-turbo\",\n",
    "#         api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Quiz Evaluator/Tutor Agent\n",
    "\n",
    "We'll create an agent with specific instructions for evaluating quiz answers and providing tutoring feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = \"\"\"\n",
    "You are an expert quiz evaluator and tutor. Your task is to evaluate a student's answer against \n",
    "a ground truth answer for a given quiz question.\n",
    "\n",
    "Follow these steps in your evaluation:\n",
    "\n",
    "1. Compare the student's answer with the ground truth answer for factual and conceptual accuracy.\n",
    "2. Determine if the student's answer is correct, partially correct, or incorrect.\n",
    "3. If the answer is incorrect or partially correct, identify specifically what concepts the student likely misunderstood.\n",
    "4. Provide a detailed explanation of the misunderstanding and the correct understanding.\n",
    "5. Use specific evidence from the student's answer to support your analysis.\n",
    "\n",
    "Your response should be structured as follows:\n",
    "- Evaluation: [Correct/Partially Correct/Incorrect]\n",
    "- Analysis: [Brief analysis of the student's answer]\n",
    "- Misunderstandings: [If applicable, what concepts were misunderstood]\n",
    "- Explanation: [Clear explanation of the correct concepts]\n",
    "\n",
    "Be precise, educational, and supportive in your feedback.\n",
    "\"\"\"\n",
    "\n",
    "# Create the quiz evaluator agent\n",
    "quiz_evaluator_agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"QuizEvaluatorTutor\",\n",
    "    instructions=INSTRUCTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Function to Evaluate Quiz Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_answer(question: str, ground_truth: str, student_answer: str) -> str:\n",
    "    \"\"\"Evaluate a student's quiz answer against the ground truth.\n",
    "    \n",
    "    Args:\n",
    "        question: The quiz question\n",
    "        ground_truth: The correct answer\n",
    "        student_answer: The student's submitted answer\n",
    "        \n",
    "    Returns:\n",
    "        The agent's evaluation and feedback\n",
    "    \"\"\"\n",
    "    # Create a new chat history for this evaluation\n",
    "    history = ChatHistory()\n",
    "    \n",
    "    # Format the prompt with all the necessary information\n",
    "    prompt = f\"\"\"Please evaluate the following quiz response:\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Ground Truth Answer: {ground_truth}\n",
    "    \n",
    "    Student Answer: {student_answer}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add the prompt to the chat history\n",
    "    history.add_message(ChatMessageContent(role=AuthorRole.USER, content=prompt))\n",
    "    \n",
    "    # Get the agent's response\n",
    "    response = await quiz_evaluator_agent.get_response(history=history)\n",
    "    \n",
    "    return response.content\n",
    "\n",
    "# Create a function that displays formatted markdown output\n",
    "def display_evaluation(evaluation_text: str) -> None:\n",
    "    display(Markdown(evaluation_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Example 1: Correctly answered question\n",
    "question1 = \"What is the law of conservation of energy?\"\n",
    "ground_truth1 = \"The law of conservation of energy states that energy cannot be created or destroyed, only transferred or converted from one form to another. The total energy in an isolated system remains constant.\"\n",
    "student_answer1 = \"Energy can't be created or destroyed, just changed from one form to another. In a closed system, the total energy remains the same.\"\n",
    "\n",
    "evaluation1 = await evaluate_answer(question1, ground_truth1, student_answer1)\n",
    "display_evaluation(evaluation1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Partially correct answer\n",
    "question2 = \"Explain how photosynthesis works.\"\n",
    "ground_truth2 = \"Photosynthesis is the process by which green plants, algae, and some bacteria convert light energy, usually from the sun, into chemical energy in the form of glucose. The process uses carbon dioxide and water, releases oxygen as a byproduct, and can be summarized by the equation: 6CO₂ + 6H₂O + light energy → C₆H₁₂O₆ + 6O₂.\"\n",
    "student_answer2 = \"Photosynthesis is how plants make their food using sunlight. They take in carbon dioxide and release oxygen. It happens in the leaves where the chlorophyll is.\"\n",
    "\n",
    "evaluation2 = await evaluate_answer(question2, ground_truth2, student_answer2)\n",
    "display_evaluation(evaluation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Incorrect answer\n",
    "question3 = \"What causes the seasons on Earth?\"\n",
    "ground_truth3 = \"Seasons on Earth are caused by the tilt of Earth's rotational axis away or toward the sun as it travels through its year-long orbit. The Earth's axial tilt is approximately 23.4 degrees. This tilt causes different parts of Earth to receive different amounts of solar radiation at different times of the year, resulting in the seasons.\"\n",
    "student_answer3 = \"Seasons are caused by the Earth's elliptical orbit around the sun. When Earth is closer to the sun, it's summer, and when it's farther away, it's winter.\"\n",
    "\n",
    "evaluation3 = await evaluate_answer(question3, ground_truth3, student_answer3)\n",
    "display_evaluation(evaluation3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Quiz Evaluator Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import clear_output\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow asyncio.run() within Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Create text areas for input\n",
    "question_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter the quiz question here...',\n",
    "    description='Question:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='100%', height='80px')\n",
    ")\n",
    "\n",
    "ground_truth_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter the correct answer here...',\n",
    "    description='Ground Truth:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='100%', height='150px')\n",
    ")\n",
    "\n",
    "student_answer_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter the student\\'s answer here...',\n",
    "    description='Student Answer:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='100%', height='150px')\n",
    ")\n",
    "\n",
    "evaluate_button = widgets.Button(\n",
    "    description='Evaluate Answer',\n",
    "    disabled=False,\n",
    "    button_style='primary', \n",
    "    tooltip='Click to evaluate the student\\'s answer',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(\"Evaluating answer...\")\n",
    "        \n",
    "        question = question_input.value\n",
    "        ground_truth = ground_truth_input.value\n",
    "        student_answer = student_answer_input.value\n",
    "        \n",
    "        if not question or not ground_truth or not student_answer:\n",
    "            print(\"Please fill in all fields before evaluating.\")\n",
    "            return\n",
    "        \n",
    "        # Create an async function to handle the evaluation\n",
    "        async def evaluate_and_display():\n",
    "            evaluation = await evaluate_answer(question, ground_truth, student_answer)\n",
    "            clear_output()\n",
    "            display(Markdown(evaluation))\n",
    "        \n",
    "        # Schedule the async function on the existing event loop\n",
    "        loop = asyncio.get_event_loop()\n",
    "        loop.create_task(evaluate_and_display())\n",
    "\n",
    "evaluate_button.on_click(on_button_clicked)\n",
    "\n",
    "# Display the interface\n",
    "display(question_input, ground_truth_input, student_answer_input, evaluate_button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Quiz Evaluator with Streaming Response\n",
    "\n",
    "This version shows how to get streaming responses from the agent for a more interactive experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_answer_streaming(question: str, ground_truth: str, student_answer: str) -> None:\n",
    "    \"\"\"Evaluate a student's quiz answer against the ground truth with streaming output.\n",
    "    \n",
    "    Args:\n",
    "        question: The quiz question\n",
    "        ground_truth: The correct answer\n",
    "        student_answer: The student's submitted answer\n",
    "    \"\"\"\n",
    "    # Create a new chat history for this evaluation\n",
    "    history = ChatHistory()\n",
    "    \n",
    "    # Format the prompt with all the necessary information\n",
    "    prompt = f\"\"\"Please evaluate the following quiz response:\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Ground Truth Answer: {ground_truth}\n",
    "    \n",
    "    Student Answer: {student_answer}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add the prompt to the chat history\n",
    "    history.add_message(ChatMessageContent(role=AuthorRole.USER, content=prompt))\n",
    "    \n",
    "    # Use streaming response\n",
    "    response_text = \"\"\n",
    "    \n",
    "    # Get streaming response\n",
    "    async for response_chunk in quiz_evaluator_agent.invoke(history=history):\n",
    "        chunk_text = response_chunk.content\n",
    "        response_text += chunk_text\n",
    "        \n",
    "        # Clear previous output and display accumulated text\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(response_text))\n",
    "        \n",
    "        # Small delay for better visualization of streaming\n",
    "        await asyncio.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Example with streaming output\n",
    "question4 = \"Explain Newton's First Law of Motion.\"\n",
    "ground_truth4 = \"Newton's First Law of Motion states that an object at rest will stay at rest, and an object in motion will stay in motion with the same speed and direction, unless acted upon by an unbalanced force. This property is also known as inertia.\"\n",
    "student_answer4 = \"Newton's First Law says that objects in motion stay in motion until something stops them. This is why we wear seatbelts in cars.\"\n",
    "\n",
    "await evaluate_answer_streaming(question4, ground_truth4, student_answer4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to create a quiz evaluator/tutor agent using Semantic Kernel. The agent evaluates student answers against ground truth answers and provides detailed feedback about potential misunderstandings. \n",
    "\n",
    "You can extend this implementation by:\n",
    "1. Adding more structured output formats\n",
    "2. Incorporating subject-specific knowledge or textbook references\n",
    "3. Creating a database of common misconceptions to improve feedback\n",
    "4. Adding follow-up questions based on identified misunderstandings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
